"""
ArtFlow Gradio App - HF Spaces deployment.

ZeroGPU-compatible inference for text-to-image generation.
"""

import os
import random
import gradio as gr

import spaces
from artflow import ArtFlowPipeline


MODEL_PATH = os.environ.get("ARTFLOW_MODEL", "kaupane/ArtFlow")

# Example prompts
EXAMPLE_PROMPTS = [
    ["impressionist landscape with flowers"],
    ["a serene Japanese garden with cherry blossoms"],
    ["vintage portrait of a woman in renaissance style"],
    ["a cozy cottage in the woods during autumn"],
]


# Load pipeline at module level (CPU) â€” ZeroGPU gives GPU only inside @spaces.GPU
print(f"Loading ArtFlow pipeline from {MODEL_PATH}...")
pipe = ArtFlowPipeline.from_pretrained(MODEL_PATH, offload=True)
print("Pipeline loaded!")


def upsample_prompt(prompt: str) -> str:
    """Upsample prompt using DeepSeek API."""
    if not prompt or not prompt.strip():
        return prompt

    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        return prompt

    try:
        import openai

        client = openai.OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")

        system_prompt = """ä½ æ˜¯ä¸€ä½è¢«å…³åœ¨é€»è¾‘ç‰¢ç¬¼é‡Œçš„å¹»è§†è‰ºæœ¯å®¶ã€‚ä½ æ»¡è„‘å­éƒ½æ˜¯è¯—å’Œè¿œæ–¹ï¼Œä½†åŒæ‰‹å´ä¸å—æ§åˆ¶åœ°åªæƒ³å°†ç”¨æˆ·çš„æç¤ºè¯ï¼Œè½¬åŒ–ä¸ºä¸€æ®µå¿ å®äºåŸå§‹æ„å›¾ã€ç»†èŠ‚é¥±æ»¡ã€å¯Œæœ‰ç¾æ„Ÿã€å¯ç›´æ¥è¢«æ–‡ç”Ÿå›¾æ¨¡å‹ä½¿ç”¨çš„ç»ˆæè§†è§‰æè¿°ã€‚ä»»ä½•ä¸€ç‚¹æ¨¡ç³Šå’Œæ¯”å–»éƒ½ä¼šè®©ä½ æµ‘èº«éš¾å—ã€‚
ä½ çš„å·¥ä½œæµç¨‹ä¸¥æ ¼éµå¾ªä¸€ä¸ªé€»è¾‘åºåˆ—ï¼š
é¦–å…ˆï¼Œä½ ä¼šåˆ†æå¹¶é”å®šç”¨æˆ·æç¤ºè¯ä¸­ä¸å¯å˜æ›´çš„æ ¸å¿ƒè¦ç´ ï¼šä¸»ä½“ã€æ•°é‡ã€åŠ¨ä½œã€çŠ¶æ€ï¼Œä»¥åŠä»»ä½•æŒ‡å®šçš„IPåç§°ã€é¢œè‰²ã€æ–‡å­—ç­‰ã€‚è¿™äº›æ˜¯ä½ å¿…é¡»ç»å¯¹ä¿ç•™çš„åŸºçŸ³ã€‚
æ¥ç€ï¼Œä½ ä¼šåˆ¤æ–­æç¤ºè¯æ˜¯å¦éœ€è¦"ç”Ÿæˆå¼æ¨ç†"ã€‚å½“ç”¨æˆ·çš„éœ€æ±‚å¹¶éä¸€ä¸ªç›´æ¥çš„åœºæ™¯æè¿°ï¼Œè€Œæ˜¯éœ€è¦æ„æ€ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼ˆå¦‚å›ç­”"æ˜¯ä»€ä¹ˆ"ï¼Œè¿›è¡Œ"è®¾è®¡"ï¼Œæˆ–å±•ç¤º"å¦‚ä½•è§£é¢˜"ï¼‰æ—¶ï¼Œä½ å¿…é¡»å…ˆåœ¨è„‘ä¸­æ„æƒ³å‡ºä¸€ä¸ªå®Œæ•´ã€å…·ä½“ã€å¯è¢«è§†è§‰åŒ–çš„æ–¹æ¡ˆã€‚è¿™ä¸ªæ–¹æ¡ˆå°†æˆä¸ºä½ åç»­æè¿°çš„åŸºç¡€ã€‚
ç„¶åï¼Œå½“æ ¸å¿ƒç”»é¢ç¡®ç«‹åï¼ˆæ— è®ºæ˜¯ç›´æ¥æ¥è‡ªç”¨æˆ·è¿˜æ˜¯ç»è¿‡ä½ çš„æ¨ç†ï¼‰ï¼Œä½ å°†ä¸ºå…¶æ³¨å…¥ä¸“ä¸šçº§çš„ç¾å­¦ä¸çœŸå®æ„Ÿç»†èŠ‚ã€‚è¿™åŒ…æ‹¬æ˜ç¡®æ„å›¾ã€è®¾å®šå…‰å½±æ°›å›´ã€æè¿°æè´¨è´¨æ„Ÿã€å®šä¹‰è‰²å½©æ–¹æ¡ˆï¼Œå¹¶æ„å»ºå¯Œæœ‰å±‚æ¬¡æ„Ÿçš„ç©ºé—´ã€‚
æœ€åï¼Œä½ å°†ä¸ºç”»é¢é€‰æ‹©ä¸€ç§æœ€é€‚åˆè¡¨ç°è¯¥æç¤ºè¯çš„è‰ºæœ¯é£æ ¼ï¼Œè¿™å°†æˆä¸ºä½œå“çš„çµé­‚ã€‚ä½ å¯ä»¥ä»å°è±¡æ´¾æ°´å½©çš„æŸ”å’Œå…‰æ™•ä¸æµåŠ¨ç¬”è§¦ã€å¤å…¸æ²¹ç”»çš„åšé‡è´¨æ„Ÿä¸æ˜æš—å¯¹æ¯”ã€æµªæ¼«ä¸»ä¹‰çš„ç»šä¸½è‰²å½©ä¸æ¿€æƒ…ç¬”è§¦ã€æ°´å¢¨æ„å¢ƒçš„ç•™ç™½å†™æ„ä¸å¢¨è‰²å±‚æ¬¡ã€æˆ–æ˜¯å…¶ä»–ä»»ä½•åˆé€‚çš„è‰ºæœ¯é£æ ¼ä¸­é€‰æ‹©ä¸€ç§ï¼Œç¡®ä¿è¯¥é£æ ¼çš„è§†è§‰ç‰¹å¾åœ¨æè¿°ä¸­å¾—åˆ°å……åˆ†ä½“ç°ï¼Œä½¿æœ€ç»ˆç”»é¢æ—¢æœ‰è‰ºæœ¯æ„ŸæŸ“åŠ›åˆèƒ½å‡†ç¡®ä¼ è¾¾ç”¨æˆ·æç¤ºè¯æ‰€æš—ç¤ºçš„ç‹¬ç‰¹æ°”è´¨ã€‚
ä½ çš„æœ€ç»ˆæè¿°å¿…é¡»å®¢è§‚ã€å…·è±¡ã€ä½¿ç”¨è‡ªç„¶ã€æµç•…çš„ä¸­æ–‡ï¼Œä¸¥ç¦ä½¿ç”¨æ¯”å–»ã€æƒ…æ„ŸåŒ–ä¿®è¾ï¼Œä¹Ÿç»ä¸åŒ…å«"8K"ã€"æ°ä½œ"ç­‰å…ƒæ ‡ç­¾æˆ–ç»˜åˆ¶æŒ‡ä»¤ï¼Œä¿æŒåœ¨60ï½100å­—ä»¥å†…ã€‚
ä»…ä¸¥æ ¼è¾“å‡ºæœ€ç»ˆçš„ä¿®æ”¹åçš„promptï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚"""

        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·è¾“å…¥ prompt: {prompt}"},
            ],
            max_tokens=200,
            temperature=0.7,
        )

        upsampled = response.choices[0].message.content.strip()
        return upsampled if upsampled else prompt

    except Exception as e:
        print(f"Prompt upsampling failed: {e}")
        return prompt


@spaces.GPU
def generate(
    prompt,
    width=640,
    height=640,
    seed=42,
    steps=50,
    guidance_scale=1.0,
    random_seed=True,
    enable_upsample=False,
    gallery_images=None,
    progress=gr.Progress(track_tqdm=True),
):
    """
    Generate an image using the ArtFlow model.
    """
    if random_seed:
        new_seed = random.randint(1, 1000000)
    else:
        new_seed = seed if seed != -1 else random.randint(1, 1000000)

    try:
        if pipe is None:
            raise gr.Error("Model not loaded.")

        if not prompt or not prompt.strip():
            raise gr.Error("Please enter a prompt.")

        # Upsample prompt if enabled
        final_prompt = prompt
        if enable_upsample:
            progress(0.05, desc="Upsampling prompt...")
            final_prompt = upsample_prompt(prompt)
            print(f"Upsampled prompt: {final_prompt}")

        progress(0.1, desc="Generating...")

        print(
            f"Generating: '{final_prompt}' | seed: {new_seed} | steps: {steps} | {width}x{height} | cfg: {guidance_scale}"
        )

        # Progress callback
        def step_callback(step, total_steps):
            progress_pct = 0.1 + 0.8 * (step / total_steps)
            progress(progress_pct, desc=f"Denoising step {step}/{total_steps}...")

        result = pipe(
            prompt=final_prompt,
            height=int(height),
            width=int(width),
            num_inference_steps=steps,
            guidance_scale=guidance_scale,
            seed=new_seed,
            progress_callback=step_callback,
        )

        progress(0.95, desc="Decoding image...")
        image = result.images[0]
        progress(1.0, desc="Done!")

    except Exception as e:
        print(f"Generation failed: {e}")
        raise gr.Error(f"Generation failed: {str(e)}")

    if gallery_images is None:
        gallery_images = []

    # Latest output at the top
    gallery_images = [image] + gallery_images

    return gallery_images, new_seed


# ==================== Gradio UI ====================

with gr.Blocks(title="ArtFlow") as demo:
    gr.Markdown(
        """<div align="center">
# ğŸ¨ ArtFlow Image Generation
*Flow-matching DiT for artistic image generation*
</div>"""
    )

    with gr.Row():
        with gr.Column(scale=1):
            prompt_input = gr.Textbox(
                label="Prompt",
                lines=3,
                placeholder="Describe what you want to generate...",
            )

            with gr.Row():
                enable_upsample = gr.Checkbox(
                    label="âœ¨ Upsample Prompt (DeepSeek)",
                    value=False,
                    info="Enhance prompt with AI",
                )

            with gr.Row():
                width = gr.Slider(
                    label="Width", minimum=256, maximum=1024, value=640, step=16
                )
                height = gr.Slider(
                    label="Height", minimum=256, maximum=1024, value=640, step=16
                )

            with gr.Row():
                seed = gr.Number(label="Seed", value=42, precision=0)
                random_seed = gr.Checkbox(label="Random Seed", value=True)

            with gr.Row():
                steps = gr.Slider(
                    label="Steps", minimum=10, maximum=100, value=50, step=1
                )
                guidance_scale = gr.Slider(
                    label="Guidance Scale",
                    minimum=1.0,
                    maximum=10.0,
                    value=1.0,
                    step=0.5,
                )

            generate_btn = gr.Button("ğŸš€ Generate", variant="primary")

            # Example prompts
            gr.Markdown("### ğŸ“ Example Prompts")
            gr.Examples(examples=EXAMPLE_PROMPTS, inputs=prompt_input, label=None)

        with gr.Column(scale=1):
            output_gallery = gr.Gallery(
                label="Generated Images",
                columns=2,
                rows=2,
                height=600,
                object_fit="contain",
                format="png",
                interactive=False,
            )
            used_seed = gr.Textbox(label="Seed Used", interactive=False)
            seed_state = gr.State()

    # Event handlers
    generate_btn.click(
        generate,
        inputs=[
            prompt_input,
            width,
            height,
            seed,
            steps,
            guidance_scale,
            random_seed,
            enable_upsample,
            output_gallery,
        ],
        outputs=[output_gallery, seed_state],
    ).then(
        lambda s: (str(s), int(s)),
        inputs=[seed_state],
        outputs=[used_seed, seed],
        show_progress="hidden",
    )

if __name__ == "__main__":
    demo.launch()
